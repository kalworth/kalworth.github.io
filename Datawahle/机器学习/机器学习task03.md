# 李宏毅机器学习第三章任务

## Error的来源

在回顾上一章时我们讨论了机器学习中可能会遇到的一些影响结果的情况，如何来评判这种Error呢？

常见模型的主要Error来源主要有两个，分别为bios和variance

即Error = Bias + Variance

### Bias

Bias是 “用**所有可能的**训练数据集训练出的**所有模型**的输出的 **平均值** ” 与 “真实模型”的输出值之间的差异

Error反映的是整个模型的准确度，Bias反映的是模型在样本上的输出与真实值之间的误差，即模型本身的精准度

在刚开始训练时由于训练量比较小，bios数值还比较大，因为它本身在不停地接近真实模型所反应的数值，而在确保训练数据准确性的情况下，这个数值会随着训练量的增大会无限下降，

### variance


假设我们现在有一组训练数据，需要训练一个模型（基于梯度的学习，不包括最近邻等方法）。在训练过程的最初，bias很大，因为我们的模型还没有来得及开始学习，也就是与“真实模型”差距很大。然而此时variance却很小，因为 **训练数据集（training data）还没有来得及对模型产生影响** ，所以此时将模型应用于“不同的”训练数据集也不会有太大差异。

而当数据训练量不断扩大时，各训练数据集之间的差异就开始发挥作用，

因为我们除了学习到关于真实模型的信息，还学到了 **许多具体的，只针对我们使用的训练集** （真实数据的子集）的信息。而 **不同的可能训练数据集（真实数据的子集）之间的某些特征和噪声是不一致的** ，这就导致了我们的模型在很多其他的数据集上就无法获得很好的效果，也就是所谓的**overfitting**。


## 估测Error

在实际情况中我们往往是不清楚我们想要的那个真实的function，所以我们只能收集大量数据来训练接近我们想要的那个function。

![](https://oss.linklearner.com/leeml/chapter5/res/chapter5-3.png)

这个过程就像打靶，*f*^就是我们的靶心，***f**∗ 就是我们投掷的结果。如上图所示，f*^ 与**f**∗ 之间蓝色部分的差距就是偏差和方差导致的。


### 估测变量x的偏差和方差

#### 评估x的偏差

假设 x**x** 的平均值是 \mu**μ**，方差为 \sigma^2**σ**2

评估平均值要怎么做呢？

* 首先拿到 N**N** 个样本点：\{x^1,x^2,···,x^N\}**{**x**1**,**x**2**,**⋅**⋅**⋅**,**x**N**}
* 计算平均值 m**m**, 得到 m=\frac{1}{N}\sum_n x^n \neq \mu**m**=**N**1∑**n****x**n****=**μ**

#### 估测变量x的方差

![](https://oss.linklearner.com/leeml/chapter5/res/chapter5-6.png)


### 为什么会有很多的模型?

这里以笔者最熟悉的自动驾驶模型做介绍

在采集数据时，在不同场景，不同环境下的采集效果不同，同一个场景，多次采集时得到的数据依然存在偏差，所以对这些数据进行训练时的model是不一样的，而最终我们的模型会受到所有训练结果的干扰

![](https://oss.linklearner.com/leeml/chapter5/res/chapter5-10.png)


#### 考虑不同模型的方差


一次模型的方差就比较小的，也就是是比较集中，离散程度较小。而5次模型的方差就比较大，同理散布比较广，离散程度较大。

所以用比较简单的模型，方差是比较小的（就像射击的时候每次的时候，每次射击的设置都集中在一个比较小的区域内）。如果用了复杂的模型，方差就很大，散布比较开。

这也是因为简单的模型受到不同训练集的影响是比较小的。


#### 考虑不同模型的偏差

![](https://oss.linklearner.com/leeml/chapter5/res/chapter5-11.png)


结果可视化，一次平均的**f**ˉ 没有5次的好，虽然5次的整体结果离散程度很高。

一次模型的偏差比较大，而复杂的5次模型，偏差就比较小。

直观的解释：简单的模型函数集的space比较小，所以可能space里面就没有包含靶心，肯定射不中。而复杂的模型函数集的space比较大，可能就包含的靶心，只是没有办法找到确切的靶心在哪，但足够多的，就可能得到真正的 f¯


## 怎么判断？

关于拟合的三种情况在上一章已经阐述，这一章不再过多介绍


## 模型选择

现在在偏差和方差之间就需要一个权衡
想选择的模型，可以平衡偏差和方差产生的错误，使得总错误最小
但是下面这件事最好不要做：

![](https://oss.linklearner.com/leeml/chapter5/res/chapter5-15.png)

用训练集训练不同的模型，然后在测试集上比较错误，模型3的错误比较小，就认为模型3好。但实际上这只是你手上的测试集，真正完整的测试集并没有。比如在已有的测试集上错误是0.5，但有条件收集到更多的测试集后通常得到的错误都是大于0.5的。

### 常见的划分训练集的方法

#### 留出法

（1）将数据集划分为互斥的两个部分，一部分是训练集，一部分是测试集

![](https://pic1.zhimg.com/80/v2-490c52f84cbe44fdca92a6c12d0f4f80_720w.png)

（2）划分时要尽量保证训练集和测试集数据分布的一致性，例如在分类样本中有1000个正样本，100个负样本，那么训练集和测试集中的正负样本比例也要基本遵循10：1这个比例

（3）为了保证划分结果的随机性，可以将数据集多次随机划分，然后对多次划分结果取平均值

（4）训练集和测试集的划分比例没有固定的值，通常将大约2/3~4/5的样本用于训练，最常见的训练集测试集比例有7：3或8：2

#### 交叉验证法


（1） 先将数据集划分为k个大小相似的互斥子集，每个子集尽可能保持数据分布的一致性

（2） 然后每次选k-1个子集一组作为训练集，剩下一个子集作为测试集，共有k种分发得到k组训练集和测试集

（3） 进行k此训练和测试，对结果取平均值

交叉验证法评估结果的稳定性和保真性在很大程度上取决于k的取值，为了强调这一点，通常把交叉验证法称为”k折交叉验证”（k-fold cross validation），k通常取10—10折交叉验证。

![](https://pic3.zhimg.com/80/v2-fd0858ee8ad9e74fd30146bdbc954eb6_720w.jpg)

交叉验证的好处就是从有限的数据中尽可能挖掘多的信息，从各种角度去学习我们现有的有限的数据，避免出现局部的极值。缺点就是，当数据集比较大时，训练模型的开销较大

#### 自助法


当样本数量比较少时，为了充分利用样本数据，可采取自助法

（1） 每次随机从数据集（有m个样本）抽取一个样本，然后再放回（也就是说可能被重复抽出），m次后得到有m个样本的数据集，将其作为训练集

（2） 通过概率计算，经过m次抽样后会有约1/3的样本，始终不会被抽到，这部分数据可以用来测试

![img](https://pic3.zhimg.com/80/v2-5d10ec6d892b2b0848faa9d6943f2c72_720w.png)

自助法产生的测试集改变了初始数据集的分布，这会引入误差，因此在数据量足够时，采用留出法和交叉验证法较好
