# åä¸ºCVèµ›äº‹ç»éªŒæ€»ç»“

æœ€è¿‘å’Œå“¥ä»¬ä¸€èµ·å‚åŠ äº†Datawahleä¸€èµ·ç»„ç»‡çš„CVæ–¹å‘å®è·µèµ›äº‹ï¼Œä¹Ÿç®—æ˜¯å–å¾—äº†ä¸å°çš„è¿›æ­¥å’Œæ”¶è·ï¼Œåœ¨è¿™é‡Œæ€»ç»“ä¸€ä¸‹è¿™æ¬¡çš„ç»éªŒå’Œä¼˜åŒ–ç­–ç•¥ã€‚

## æ•°æ®è§‚å¯Ÿå’Œå¤„ç†

èµ›äº‹å¼€å§‹åæˆ‘ä»¬æ‹¿åˆ°äº†Datawhaleçš„å­¦ä¹ æ•°æ®ï¼Œå¤§çº¦3ä¸ªGå·¦å³ï¼Œè¿™ä¸ªèµ›é“çš„ä¸»è¦å‘½é¢˜å°±æ˜¯è¯†åˆ«å‡ºé—®é¢˜èµ›é“ï¼Œé—®é¢˜èµ›é“åœ¨è·¯çº¿æ ‡è¯†ä¸Šå¾€å¾€ä¼šå‡ºç°è¶Šç•Œæˆ–è€…å’Œå…¶ä»–æ ‡è¯†æ¨¡ç³Šçš„ç‰¹å¾ï¼Œå…³é”®å°±åœ¨äºæå–è¿™äº›ç‰¹å¾ã€‚
ä¸€å¼€å§‹é‡‡ç”¨çš„æ˜¯Datawhaleå®˜æ–¹æä¾›çš„baselineæ•°æ®å¤„ç†ï¼Œä¹Ÿå°±æ˜¯éšæœºæ—‹è½¬å›¾åƒï¼Œä½†æ˜¯åœ¨è§‚å¯Ÿåï¼Œæˆ‘ä»¬å¼•å…¥äº†æ›´ä¸ºæ ‡å‡†çš„å˜æ¢è¿›ä¸€æ­¥æ‰©å……æ•°æ®é‡ï¼Œå› ä¸ºè½¦é“å¾€å¾€æ’å¸ƒæ˜¯æ¯”è¾ƒè§„å¾‹çš„æˆ‘ä»¬ä¸å¸Œæœ›è¿‡äºéšæœºçš„æ—‹è½¬æ¥å½±å“æ¨¡å‹çš„å‡†ç¡®åº¦ï¼ŒåŒæ—¶åœ¨epochè¾ƒå¤§æ—¶ä¹Ÿèƒ½å¤Ÿä¿è¯ä¸å‡ºç°è¿‡åº¦å­¦ä¹ ï¼Œæœ€åå–å¾—äº†0.02çš„AUCè¿›æ­¥


```python
trfs = transforms.Compose([
    transforms.Resize((224, 224)),
    # transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(90),
    transforms.RandomRotation((90)),
    transforms.RandomRotation(30, center=(0, 0)),
    transforms.RandomRotation(30, center=(0, 0)),
    transforms.ColorJitter(brightness=0.5, contrast=0.5, hue=0.5),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])
```


## è®­ç»ƒé›†ä»¥åŠéªŒè¯é›†åˆ’åˆ†

åœ¨å­¦ä¹ ç‰ˆæ•°æ®å†…ï¼Œæ•°æ®æ•°é‡æœ‰é™ï¼Œè€Œåœ¨å®˜æ–¹æä¾›çš„å…¨é‡æ•°æ®é›†å†…ï¼Œè®­ç»ƒé›†çš„æ•°é‡å¤§å¤§å¢åŠ ï¼Œä½†æ˜¯å­˜åœ¨ä¸€éƒ¨åˆ†æœªè¢«æ ‡è¯†çš„æ•°æ®ï¼Œåœ¨ğŸ®è€å¸ˆçš„æŒ‡ç‚¹ä¸‹ï¼Œæˆ‘ä»¬æœ€ç»ˆé‡‡å–äº†ä¼ªæ ‡ç­¾ç”Ÿæˆçš„ç­–ç•¥ï¼Œç”Ÿæˆäº†ä¸€éƒ¨åˆ†æ–°çš„æ•°æ®é›†ï¼Œç»è¿‡å¤„ç†åæˆ‘ä»¬æœ€ç»ˆæ‹¿åˆ°äº†éå¸¸åºå¤§çš„æ•°æ®ã€‚

### ä¼ªæ ‡ç­¾ç”Ÿæˆ

æˆ‘ä»¬é‡‡ç”¨äº†å…ˆè®­ç»ƒï¼Œåç”Ÿæˆçš„åŠæ³•ï¼Œåœ¨ä¿è¯è®­ç»ƒæ¨¡å‹è¶³å¤Ÿå¯é çš„æƒ…å†µä¸‹ï¼Œå¡äº†0.9çš„ç½®ä¿¡åº¦å¼€å§‹ç”Ÿæˆè®­ç»ƒæ ‡ç­¾ï¼ŒåŸºæœ¬å°±æ˜¯ç®€å•åœ°æ”¹äº†ä¸€ä¸‹æºä»£ç å†…çš„éªŒè¯éƒ¨åˆ†ï¼Œ
åŒæ—¶åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æˆ‘ä»¬ä¹ŸåŠ å…¥äº†è¿™éƒ¨åˆ†ç”Ÿæˆçš„æ ‡ç­¾ã€‚

```python
model = torch.load('D:/2022_2_data/network_large.pth')
model.eval()
number=1000
to_prob = nn.Softmax(dim=1)
with torch.no_grad():
    imagenames, probs = list(), list()
    for batch_idx, batch in enumerate(test_loader):
        image, _ = batch
        image = image.to('cuda')
        pred = model(image)
        prob = to_prob(pred)
        prob = list(prob.data.cpu().numpy())
        probs += prob
        number-=number
        if(number<=0):
            break

import csv
with open('submission.csv', 'w',newline = '', encoding='utf8') as fp:
    writer = csv.writer(fp)
    writer.writerow(['imagename', 'defect_prob'])
    for imagename, prob in zip(test_images, probs):
        imagename = os.path.basename(imagename)
        if(prob[0]>0.9 or prob[1]>0.9):
            if(prob[0]>prob[1]):
                pred_label = '0'
            else:
                pred_label = '1'
        else:
            continue
        writer.writerow([imagename, pred_label])
        writer.writerow([imagename, str(prob[0])])
```

åŒæ—¶å¯¹äºè®­ç»ƒæ—¶è½½å…¥æ•°æ®é›†ä¹Ÿè¦åšä¸€å®šçš„è°ƒæ•´

```python
lines = codecs.open('D:/2022_2_data/train_label/train_label/train_label.csv').readlines()
fake_lines = codecs.open('D:/2022_2_data/train_label/train_label/fake_label.csv').readlines()
train_label = pd.DataFrame({
    'image': ['train_image/labeled_data/' + x.strip().split(',')[0] for x in lines],
    'label': [x.strip().split(',')[1:] for x in lines],
})
train_label = train_label.append(pd.DataFrame({
    'image': ['train_image/unlabeled_data/' + x.strip().split(',')[0] for x in fake_lines],
    'label': [x.strip().split(',')[1:] for x in fake_lines],
}),ignore_index=True)
```

### éªŒè¯é›†åˆ’åˆ†

ä¸ºäº†ç›´è§‚åœ°è¯„ä»·æˆ‘ä»¬æ­£åœ¨è®­ç»ƒçš„æ¨¡å‹ï¼Œæˆ‘ä»¬å¯¹åŸæ•°æ®è¿›è¡Œäº†ä¸€å®šç¨‹åº¦çš„åˆ’åˆ†ï¼Œå®ç°ç­–ç•¥ä¸ºKæŠ˜åˆ’åˆ†


- äº¤å‰éªŒè¯æ•°æ®é›†åˆå§‹åŒ–

```python
#è®¾ç½®åˆ’åˆ†æ•°ç›®
k_value = 7
#æ¯ä»½å«æœ‰çš„æ ·æœ¬æ•°ç›®
each_num = int(len(train_label)/k_value)   #å–æ•´
train_label.index = list(np.arange(1,len(train_label)+1))   #é¡ºåºåŒ–ç´¢å¼•
```


- å®šä¹‰äº¤å‰éªŒè¯ä¸­è®­ç»ƒå’ŒéªŒè¯å‡½æ•°

```python
import time
def train(t_loder):
    model.train()
    start_t = time.time()
    epoch_l = 0
    epoch_t = 0
    for batch_idx, batch in enumerate(t_loder):
        optimizer.zero_grad()
        image, label = batch
        image, label = image.to('cuda'), label.to('cuda')
        output = model(image)

        l = loss(output, label)
        l.backward()
        optimizer.step()

        batch_l = l.item()
        epoch_l += batch_l
        batch_t = time.time() - start_t
        epoch_t += batch_t
        start_t = time.time()


    
        #if batch_idx % 10  == 0:
           #print(l.item(), batch_idx, len(train_loader))

    # epoch_t = epoch_t / len(train_loader)
    # epoch_l = epoch_l / len(train_loader)
    return epoch_l,epoch_t
    #print('Training times: {}/{}\tTraining loss: {:.4f}\tAverage time: {:.2f}.'.format(t_times+1,k_value-1,epoch_l,epoch_t))

def val(v_loder):
    model.eval()
    val_loss = 0
    gt_labels = []
    pred_labels = []
    with torch.no_grad():
        for batch_idx, batch in enumerate(v_loder):
            image,label = batch
            image,label = image.cuda(), label.cuda()
            output = model(image)
            preds = torch.argmax(output, 1)
            gt_labels.append(label.cpu().data.numpy())
            pred_labels.append(preds.cpu().data.numpy())
            loss_val = loss(output, label)
            val_loss += loss_val.item()*image.size(0)
    val_loss = val_loss/len(v_loder.dataset) 
    gt_labels, pred_labels = np.concatenate(gt_labels), np.concatenate(pred_labels)
    acc = np.sum(gt_labels==pred_labels)/len(pred_labels)
    return val_loss,acc
    #print('Validation Loss: {:.6f}, Accuracy: {:6f}'.format(val_loss, acc))
```

- åˆ›å»ºä½ç§»åˆ—è¡¨

```python
#å¾ªç¯å³ç§»
def list_move_right(A,a):
    for i in range(a):
        A.insert(0,A.pop())
    return A

```

- å¼€å§‹éªŒè¯

```python
for epoch in range(fold_epochs):
    #æ¨¡å‹æƒé‡ä¿å­˜å’Œè¯»å–
    save_dir = 'C:/Users/ç‹ä½³ä¹/Datawhale/test/pytorch/model/Cv_dict.pkl'
    loaded_dict = torch.load(save_dir)
    model.state_dict = loaded_dict
    ##
    epoch_tloss = 0
    val_acc = 0
    epoch_t = 0
    train_label = train_label.sample(frac=1).reset_index(drop=True)   #æ‰“ä¹±åŸæ•°æ®é›†

    for list_num in range(k_value):      # éå†å®Œä¹‹åä¸ºä¸€æ¬¡å®Œæ•´çš„KæŠ˜äº¤å‰
        move_list = list(range(0,k_value,1))
        use_list = list_move_right(move_list,list_num)

        for run_number in range(k_value-1):
            index_head = use_list.index(run_number)*each_num
            index_end = index_head + each_num
  
            ##    åˆ’åˆ†è®­ç»ƒé›†
            train_dataset = ImageSet(train_label['image'].values[index_head:index_end],train_label['new_label'].values[index_head:index_end],trfs)
            train_loader = DataLoader(train_dataset,batch_size=batch_size,shuffle=False,num_workers=0,pin_memory=True,drop_last=True)
            #      è®­ç»ƒ
            train_loss,train_time = train(train_loader)
            epoch_tloss += train_loss
            epoch_t +=train_time

    
        ##    åˆ’åˆ†éªŒè¯
        val_index_head = (use_list.index(max(use_list)))*each_num
        val_index_end = val_index_head+each_num
        val_dataset = ImageSet(train_label['image'].values[val_index_head:val_index_end],train_label['new_label'].values[val_index_head:val_index_end],trfs)
        val_loder = DataLoader(train_dataset,batch_size=batch_size,shuffle=False,num_workers=0,pin_memory=True)

        #éªŒè¯
        val_loss,acc = val(val_loder)
        val_acc += acc
        #print('Fold: {}/{}'.format(list_num+1,k_value))
    train_number = k_value*(k_value-1)
    val_number = k_value
    print('Fold_Epoch: {}/{}\ttrain Loss: {:.6f}\tval Acc: {:.4f}\tAverage time: {:.2f}.'.format(epoch+1,fold_epochs,epoch_tloss/train_number,val_acc/val_number,epoch_t/k_value))
    torch.save(model.state_dict, save_dir)
    
```

    fold: 1/7
    fold: 2/7
    fold: 3/7
    fold: 4/7
    fold: 5/7
    fold: 6/7
    fold: 7/7
    Fold_Epoch: 1/1	train Loss: 0.174783	val Acc: 0.9466	Average time: 8.67.

## ç»éªŒæ€»ç»“

å¤šå‘å‰è¾ˆè¯·æ•™ï¼ˆè‡ªå·±ä¸€ä¸ªäººæ£é¼“è¿˜æ˜¯å­¦ä¹ å¤ªæ…¢ï¼‰
æœ€ç®€å•çš„ä¼˜åŒ–ç­–ç•¥-ã€‹æé«˜ç®—åŠ›ï¼Œå®é™…æ¯”èµ›çš„è¿‡ç¨‹ä¸­ç»å¸¸ç®—åŠ›åƒç´§
åé¢ä¼šå†™å†™autodléƒ¨ç½²å’Œæœ€è¿‘åœ¨ä½“éªŒçš„é©±åŠ¨äº‘ï¼ˆç™½å«–æœ€é¦™ğŸ˜‚ï¼‰
